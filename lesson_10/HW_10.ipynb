{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5b0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae71a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "\n",
    "    # убираю пробелы в начале и в конце\n",
    "    # где знаки пунктуации окаймляю их пробелами\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # заменяю все на пробелы кроме (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # добавление маркера начала и конца к предложению\n",
    "    # чтобы модель знала, когда начинать и прекращать прогнозирование.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "181dc190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> hello , my world ! <end>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'HeLlo, My woRld! ))'\n",
    "preprocess_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa855e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Убираю акценты\n",
    "# 2. Очищаю предложения\n",
    "# 3. Возвращает пары слов в формате: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb2a7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> go . <end>\n",
      "<start> иди . <end>\n"
     ]
    }
   ],
   "source": [
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[1])\n",
    "print(ru[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f83467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4],\n",
       "        [ 5],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 6],\n",
       "        [ 0],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 0],\n",
       "        [ 9],\n",
       "        [ 2],\n",
       "        [10],\n",
       "        [ 1],\n",
       "        [11],\n",
       "        [12],\n",
       "        [ 0],\n",
       "        [ 3],\n",
       "        [ 3]]),\n",
       " <keras.preprocessing.text.Tokenizer at 0x22912ea9648>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "lang_tokenizer.fit_on_texts(a)\n",
    "tensor = lang_tokenizer.texts_to_sequences(a)\n",
    "\n",
    "tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209c75c",
   "metadata": {},
   "source": [
    "ф-ция преобразует текст в вектор чисел и делает последовательности одинаковой длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83b7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6761ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # создание очищенных входных и выходных пар\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4821959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444587, 444587)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en), len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd709f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 100000\n",
    "target_tensor, input_tensor ,targ_lang, inp_lang  = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Вычисляю максимальную длину целевых тензоров\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0810a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Создание обучающих и проверочных наборов с использованием разделения на 80-20\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# посмотрим длину\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed00a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d049086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Язык ввода; сопоставление индекса со словом\n",
      "1 ----> <start>\n",
      "20 ----> don't\n",
      "422 ----> stand\n",
      "34 ----> in\n",
      "22 ----> my\n",
      "273 ----> way\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Целевой язык; сопоставление индекса со словом\n",
      "1 ----> <start>\n",
      "7 ----> не\n",
      "1239 ----> стой\n",
      "14 ----> у\n",
      "16 ----> меня\n",
      "20446 ----> попер\n",
      "101 ----> к\n",
      "2819 ----> дороги\n",
      "24 ----> !\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Язык ввода; сопоставление индекса со словом\")\n",
    "convert(inp_lang, input_tensor_train[-10])\n",
    "print ()\n",
    "print (\"Целевой язык; сопоставление индекса со словом\")\n",
    "convert(targ_lang, target_tensor_train[-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a43c9",
   "metadata": {},
   "source": [
    "## Создаю набор данных tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf5753ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9440fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "852b7adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 11]), TensorShape([64, 15]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378db49",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deaf2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e4122",
   "metadata": {},
   "source": [
    "В слое внедрения слов форма образца изменяется с (64, 16) на (64, 11, 256),  \n",
    "то есть каждое слово становится 256-мерным вектором.  \n",
    "В слое GRU с 1024 нейронами форма образца изменяется с (64, 16, 256) на (64, 11, 1024),  \n",
    "форма скрытого вектора в слое GRU равна (64, 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2675049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма выходного сигнала энкодера: (batch size, sequence length, units) (64, 11, 1024)\n",
      "Форма скрытого состояния энкодера: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Форма выходного сигнала энкодера: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Форма скрытого состояния энкодера: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf70b2",
   "metadata": {},
   "source": [
    "## Внимание Богданау"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55881766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # форма скрытого состояния запроса == (batch_size, hidden size)\n",
    "        # запрос с формой временной оси == (batch_size, 1, hidden size)\n",
    "        # размер значения == (batch_size, max_len, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        #  размер score == (batch_size, max_length, 1)\n",
    "        # мы получаем 1 на последней оси, потому что мы применяем оценку к self.V\n",
    "        # форма тензора перед применением self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # форма  весов внимания == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # форма context_vector  после сложения == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31d159",
   "metadata": {},
   "source": [
    "здесь values Фактически, это результат, выводимый кодировщиком после прохождения через нейрон  Dense(10)    \n",
    "После слоя его форма изменилась с (64, 11, 1024) на (64, 11, 10).\n",
    "\n",
    "здесь query Фактически, это выходной вектор скрытого слоя в кодировщике.  \n",
    "Нам нужно изменить его размерность с (64, 1024) на (64, 1, 1024),  \n",
    "чтобы выполнить последующее сложение для вычисления оценки.  \n",
    "Вектор после увеличения размерности будет содержать 10 нейронов Dense   \n",
    "После слоя его форма изменилась с (64, 1, 1024) на (64, 1, 10).\n",
    "\n",
    "Форма, полученная сложением двух вышеупомянутых выходов, равна (64, 11, 10) после того, как нейрон Dense(1)  \n",
    "Получите после слоя score, Его форма принимает вид (64, 11, 1).\n",
    "\n",
    "Softmax По умолчанию применяется к последней оси, но здесь мы хотим применить его ко второй оси (т.е. ось = 1), потому что форма оценки (размер пакета, максимальная длина, размер скрытого слоя). Максимальная длина - это длина нашего ввода. Поскольку мы хотим присвоить вес каждому входу, на этой оси следует использовать softmax.  \n",
    "Проходить мимо Softmax После слоя полученная форма веса внимания и score Формы одинаковые, обе (64, 11, 1).\n",
    "Softmax Правила расчета различных осей относятся к:Какова роль оси в tf.nn.softmax (x, axis)?\n",
    "\n",
    "Вес внимания и values умножаются, чтобы получить вектор контекста, его форма (64, 11, 1024). Этот вектор также является вектором взвешенного кодирования. Вектор контекста суммируется на основе второй оси (причина та же, что и раньше), и получается окончательный вектор контекста, форма которого (64, 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6efc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4d059b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    #     self.attention = tf.keras.layers.Attention(use_scale=True, score_mode='concat')\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output форма == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x форма после прохождения через embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape после конкатенации == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # передача объединенного вектора в GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # форма выходного  слоя == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # форма выходного  слоя == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c363b0d",
   "metadata": {},
   "source": [
    "В декодере сначала использую уровень внимания, чтобы получить вектор контекста (64, 1024) и весовой коэффициент внимания (64, 11, 1).  \n",
    "\n",
    "Передаю ввод через слой внедрения слов, и его форма изменится с (64, 1) на (64, 1, 256).\n",
    "\n",
    "Добавляю измерение к вектору контекста, чтобы его форма стала (64, 1, 1024), а затем объединяю его с вводом через слой встраивания слов, чтобы получить вектор формы (64, 1, 1280).\n",
    "\n",
    "Объединенный вектор отправляется в GRU, и получается выходной вектор (64, 1, 1024) и скрытое состояние (64, 1024).\n",
    "\n",
    "Преобразую выходной вектор в двумерный массив с неизменным последним измерением, то есть форма имеет вид (64 * 1, 1024).\n",
    "\n",
    "Наконец, этот вектор проходит через полностью связанный слой, содержащий размер нейронов словаря (4935), чтобы получить окончательный результат (64, 4935)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1828c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма выходного сигнала декодера: (batch_size, vocab size) (64, 20544)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Форма выходного сигнала декодера: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5f3b3",
   "metadata": {},
   "source": [
    "### Определяю оптимизатор и функцию потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcf4c7",
   "metadata": {},
   "source": [
    "Вектор, входящий в декодер, каждый раз представляет собой слово во всех текстах в пакете, то есть форма входного вектора каждый раз равна (64, 1).  \n",
    "\n",
    "Когда во входном векторе появляется элемент 0, это означает, что текст,  \n",
    "в котором расположен этот элемент, закончился, и этот текст больше не участвует  \n",
    "в вычислении потерь, поэтому при вычислении потерь используется обработка маски,  \n",
    "чтобы установить потерю законченный текст обнулить  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f82e63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439f02c",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabd1fe",
   "metadata": {},
   "source": [
    "### Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d1d39",
   "metadata": {},
   "source": [
    "а. Передаю ввод на кодировщик, и кодировщик вернет Выход энкодера с состоянием скрытого слоя кодировщика。  \n",
    "б. Выход кодера, состояние скрытого слоя кодировщика и вход декодера (т. е.‘<start>’ ) К декодеру.  \n",
    "в. Декодер возвращает прогноз статус скрытого слоя декодера。  \n",
    "г. Состояние скрытого слоя декодера отправляется обратно в модель, и прогноз используется для вычисления потерь.  \n",
    "д. Использование учителя обязательно(Учитель форсирования) определяет следующий вход декодера.    \n",
    "PS: принуждение учителя - это технология, которая отправляет целевое слово в качестве следующего ввода в декодер.  \n",
    "е. Последний шаг - вычислить градиент и применить его к оптимизатору и обратному распространению.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0874394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_attention_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26667c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        \n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464257b1",
   "metadata": {},
   "source": [
    "### Тренировочный процесс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b73a1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae871127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.7854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:05,  2.50s/it]\u001b[A\n",
      "3it [00:07,  2.36s/it]\u001b[A\n",
      "4it [00:09,  2.31s/it]\u001b[A\n",
      "5it [00:11,  2.25s/it]\u001b[A\n",
      "6it [00:16,  3.10s/it]\u001b[A\n",
      "7it [00:19,  3.21s/it]\u001b[A\n",
      "8it [00:26,  4.15s/it]\u001b[A\n",
      "9it [00:31,  4.68s/it]\u001b[A\n",
      "10it [00:34,  4.04s/it]\u001b[A\n",
      "11it [00:39,  4.49s/it]\u001b[A\n",
      "12it [00:48,  4.01s/it]\u001b[A\n",
      "  0%|                                                                                           | 0/50 [00:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_4628/3369349150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in tqdm(enumerate(dataset.take(steps_per_epoch))):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "          print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "      # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3c561",
   "metadata": {},
   "source": [
    "# Прогноз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd63d6",
   "metadata": {},
   "source": [
    "## Функция прогноза"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50425850",
   "metadata": {},
   "source": [
    "1. Использую preprocess_sentence функция для обработки текста ascii;  \n",
    "2. Преобразую текст в цифровой вектор;  \n",
    "3. Преобразую цифровой вектор в тензор;  \n",
    "4. Инициализирую скрытое состояние кодировщика;  \n",
    "5. Ввожу цифровой тензор и начальное скрытое состояние в кодировщик;  \n",
    "6. Инициализирую вход декодера;  \n",
    "7. Дословно ввожу декодер, чтобы получить предсказанный текст.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27900379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # Сохраните веса внимания для последующего рисования\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # Прогнозируемый идентификатор возвращается в модель\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc5f7f",
   "metadata": {},
   "source": [
    "## Функция отображения веса внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddd085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69525815",
   "metadata": {},
   "source": [
    "## Функция перевода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d990395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "#     attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "#     plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76e3dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22926777b08>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# восстановление последней контрольной точки в checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f2ff055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> see you later <end>\n",
      "Predicted translation: увидимся позже . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('See you later') # До скорого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2f17732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> have a nice day <end>\n",
      "Predicted translation: счастливого дня . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Have a nice day')# хорошего дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b50d05e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how are you doing ? <end>\n",
      "Predicted translation: как поживаете ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('How are you doing?') # как дела?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3354b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how about you ? <end>\n",
      "Predicted translation: как насч т ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('How about you?') # а как у тебя дела?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c619fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> thank you very much <end>\n",
      "Predicted translation: спасибо большое спасибо . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Thank you very much') # Спасибо большое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1810be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i appreciate it <end>\n",
      "Predicted translation: я ценю это . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('I appreciate it') # я ценю это"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbc9d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> always welcome <end>\n",
      "Predicted translation: все будут лучше . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Always welcome') # Всегда пожалуйста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7cf6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> not at all <end>\n",
      "Predicted translation: вс не вс равно . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Not at all') # Не за что"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "064d55f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> excuse me <end>\n",
      "Predicted translation: простите меня . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Excuse me') # Простите"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef3deb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> no problem ! <end>\n",
      "Predicted translation: ни у кого не было . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('No problem!') # Без проблем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f59df362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i m absolutely sure <end>\n",
      "Predicted translation: я проспал я . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('I’m absolutely sure') # Я совершенно уверен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e669188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> maybe <end>\n",
      "Predicted translation: да те . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Maybe') # Может быть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "305d16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> as far as i know <end>\n",
      "Predicted translation: делайте как я знаю как . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('As far as I know') # Насколько я знаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0aad8079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> it seems to me <end>\n",
      "Predicted translation: это кажется мне . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('It seems to me') # Мне кажется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7289321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> to be honest <end>\n",
      "Predicted translation: поешьте , будь честен . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('To be honest') # Честно говоря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23d4731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how much is ? <end>\n",
      "Predicted translation: сколько стоят ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('How much is …?') # Сколько стоит …?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1901617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how do i go to ? <end>\n",
      "Predicted translation: как мне пойти ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('How do I go to…?') # Как мне пройти …?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c94b0141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> would you like ? <end>\n",
      "Predicted translation: разве бы желаете ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Would you like…?') # Не желаете ли вы…?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9118b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> can i offer you ? <end>\n",
      "Predicted translation: я могу вам позвонить ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Can I offer you…?') # Могу я предложить вам…?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "238907aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i recommend you <end>\n",
      "Predicted translation: я надеюсь тебя . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('I recommend you …') # Я рекомендую вам …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "556975a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> strange that i did not know him then , that friend of mine ! i did not even show him then one friendly sign <end>\n",
      "Predicted translation: я не сделал е никто не сделал е никто не сделал е никто не сделал \n"
     ]
    }
   ],
   "source": [
    "# Как странно: я не знал его,Хоть мы – друзья.Расположенья своего Не выдал я.\n",
    "translate('Strange that I did not know him then,That friend of mine!I did not even show him then One friendly sign;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d6aee",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "я обучал модель 8 эпох, даже на столь небольшм обучении модель показала вполне приемлимые результаты, конечно есть к чему стремиться дальше"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

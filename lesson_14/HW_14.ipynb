{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90913e72",
   "metadata": {},
   "source": [
    "Задание\n",
    "  \n",
    "взять данные из  \n",
    "https://www.kaggle.com/datasets/mrapplexz/bashim-quotes  \n",
    "обучить модель GPT для генерации своих цитат  \n",
    "  \n",
    "взять новостные данные из  \n",
    "https://github.com/natasha/corus    \n",
    "load_lenta2  \n",
    "нам понадобиться сам текст и заголовок  \n",
    "обучить модель T5/ или GPT для генерации заголовков для статей  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2aafc",
   "metadata": {},
   "source": [
    "# загрузим данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bb222",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/mrapplexz/bashim-quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db5ea8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"bankholdup/rugpt3_song_writer\"\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a00b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "092f16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfc83120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d073b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec = pd.read_json('dataset.jsonl', lines=True).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "whole-sally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81497, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d4b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec = df_rec.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0a4ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clear_text(text):\n",
    "    clr_text = re.sub(r\"<.*?>\", \" \", text).lower()\n",
    "    clr_text = summary = re.sub(r\"\\s\", \" \", clr_text)\n",
    "    return clr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51408568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451487</th>\n",
       "      <td>2018-07-27 07:12:00+00:00</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>Ккккротов: опечатка \"зов передков\" точнее отра...</td>\n",
       "      <td>ккккротов: опечатка \"зов передков\" точнее отра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398613</th>\n",
       "      <td>2008-08-22 10:54:00+00:00</td>\n",
       "      <td>38421.0</td>\n",
       "      <td>Анна**ЗАКОНЧИЛА ШКОЛУ!!!\"Викторова вступила в ...</td>\n",
       "      <td>анна**закончила школу!!!\"викторова вступила в ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456044</th>\n",
       "      <td>2019-05-29 07:13:00+00:00</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>stupidchemist: На моё место \"проще химиков раз...</td>\n",
       "      <td>stupidchemist: на моё место \"проще химиков раз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431520</th>\n",
       "      <td>2014-12-16 08:12:00+00:00</td>\n",
       "      <td>14257.0</td>\n",
       "      <td>XXX: Мне нравилось в 90-е, я бы с удовольствие...</td>\n",
       "      <td>xxx: мне нравилось в 90-е, я бы с удовольствие...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397561</th>\n",
       "      <td>2008-06-30 13:54:00+00:00</td>\n",
       "      <td>28256.0</td>\n",
       "      <td>Восторженный возглас нашего препода по логике:...</td>\n",
       "      <td>восторженный возглас нашего препода по логике:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date   rating  \\\n",
       "id                                          \n",
       "451487 2018-07-27 07:12:00+00:00   2262.0   \n",
       "398613 2008-08-22 10:54:00+00:00  38421.0   \n",
       "456044 2019-05-29 07:13:00+00:00   2362.0   \n",
       "431520 2014-12-16 08:12:00+00:00  14257.0   \n",
       "397561 2008-06-30 13:54:00+00:00  28256.0   \n",
       "\n",
       "                                                     text  \\\n",
       "id                                                          \n",
       "451487  Ккккротов: опечатка \"зов передков\" точнее отра...   \n",
       "398613  Анна**ЗАКОНЧИЛА ШКОЛУ!!!\"Викторова вступила в ...   \n",
       "456044  stupidchemist: На моё место \"проще химиков раз...   \n",
       "431520  XXX: Мне нравилось в 90-е, я бы с удовольствие...   \n",
       "397561  Восторженный возглас нашего препода по логике:...   \n",
       "\n",
       "                                               clear_text  \n",
       "id                                                         \n",
       "451487  ккккротов: опечатка \"зов передков\" точнее отра...  \n",
       "398613  анна**закончила школу!!!\"викторова вступила в ...  \n",
       "456044  stupidchemist: на моё место \"проще химиков раз...  \n",
       "431520  xxx: мне нравилось в 90-е, я бы с удовольствие...  \n",
       "397561  восторженный возглас нашего препода по логике:...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec[\"clear_text\"] = df_rec[\"text\"].apply(lambda x: clear_text(x))\n",
    "df_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5333d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_rec.loc[:, 'clear_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fca456b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "451487    ккккротов: опечатка \"зов передков\" точнее отра...\n",
       "398613    анна**закончила школу!!!\"викторова вступила в ...\n",
       "456044    stupidchemist: на моё место \"проще химиков раз...\n",
       "431520    xxx: мне нравилось в 90-е, я бы с удовольствие...\n",
       "397561    восторженный возглас нашего препода по логике:...\n",
       "                                ...                        \n",
       "417334    na-ta: срочно! затопили соседей! хелп! после 8...\n",
       "430027    xxx: нашёл в ленте крик души какого-то школьни...\n",
       "442396    ххх: калифорния устраивает референдум по отсое...\n",
       "399826    xxx хочу 201розу  xxx не выйду за тебя,пока ты...\n",
       "414686    ххх: сидим в одной комнате с начальником отдел...\n",
       "Name: clear_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "207d5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_text_files(data_json, dest_path):\n",
    "#     f = open(dest_path, 'w')\n",
    "    with open(dest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        data = ''\n",
    "        for texts in data_json:\n",
    "            summary = str(texts).strip()\n",
    "    #         summary = re.sub(r\"<.*?>\", \" \", summary)\n",
    "    #         summary = re.sub(r\"\\s\", \" \", summary)\n",
    "            data += summary + \"  \"\n",
    "    #     with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(html)\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07da444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1668f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_text_files(train,'train_dataset.txt')\n",
    "build_text_files(test,'test_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be7c73da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 8500\n",
      "Test dataset length: 1500\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset length: \"+ str(len(train)))\n",
    "print(\"Test dataset length: \"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a2782d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "415125    эon: допустим, я хочу телепортироваться из точ...\n",
       "392895    ххх: я сегодня вычислил, за сколько пылесос вы...\n",
       "431520    xxx: мне нравилось в 90-е, я бы с удовольствие...\n",
       "226142    nansee: вот крашусь и думаю: а ведь в фотошопе...\n",
       "399450    катерина >>  мих, а что такое рапидшара?  tera...\n",
       "Name: clear_text, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a66d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "#sberbank-ai/rugpt3large_based_on_gpt2\n",
    "#sberbank-ai/rugpt3medium_based_on_gpt2\n",
    "#sberbank-ai/rugpt3small_based_on_gpt2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8bbae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voron\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\data\\datasets\\language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130074b",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8d63a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51805732edbc416d841fc4ea20b6085b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "869a7ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voron\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "    \"phrase\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e09a1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d15e57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voron\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2190/2190 7:02:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.091000</td>\n",
       "      <td>3.931326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.965500</td>\n",
       "      <td>3.919243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2190, training_loss=4.033529481931364, metrics={'train_runtime': 25376.7375, 'train_samples_per_second': 0.345, 'train_steps_per_second': 0.086, 'total_flos': 572098904064000.0, 'train_loss': 4.033529481931364, 'epoch': 2.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e5018",
   "metadata": {},
   "source": [
    "# generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c22a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prefix):\n",
    "    tokens = tokenizer(prefix, return_tensors='pt')\n",
    "    size = tokens['input_ids'].shape[1]\n",
    "\n",
    "    output = model.generate(\n",
    "        **tokens, \n",
    "        #end_token=end_token_id,\n",
    "        do_sample=False,\n",
    "        max_length=size+50, \n",
    "        early_stopping=True,\n",
    "        length_penalty=2.0,\n",
    "        repetition_penalty=8., \n",
    "        temperature=0.5,\n",
    "        num_beams=3,\n",
    "        no_repeat_ngram_size=5\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0])\n",
    "    result = decoded[len(prefix):]\n",
    "    return prefix + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60aee52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ну ты собираешься идти?  xxx: у нас в городе есть один магазин, где можно купить все что душе угодно. yyy: а я вот не могу себе позволить такую роскошь - покупать всякую фигню на развес и ходить с ней по магазину...\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"ну ты собираешься идти?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e888394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "заводи, поехали.  xxx: а у нас в городе есть такой магазинчик - \"сувениры\". там можно купить что-нибудь на память о детстве и юности... yyy: ну так вот я тебе сейчас расскажу историю про то, как\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"заводи, поехали\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77d61101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "захвати в магазине что-нибудь к чаю.  xxx: у меня есть знакомый, который работает на заводе по переработке нефти и газа (входит в холдинг \"нефтегазовая компания\") - он очень любит свою работу! yyy: а я вот не люблю\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"захвати в магазине что-нибудь к чаю\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-bailey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb97b875",
   "metadata": {},
   "source": [
    "Задание\n",
    "\n",
    "Взять тот же датасет, который был на вебинаре и предобученную модель для задачи суммаризации\n",
    "1. Проверить насколько хорошо она суммаризирует\n",
    "2.(дополнительно) Сделать генерацию заголовков для статьи (обучить модель для генерации заголовков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600f7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\VoronkovSergey\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\IlyaGusev--gazeta\\ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457 (last modified on Wed Aug 10 21:41:36 2022) since it couldn't be found locally at IlyaGusev/gazeta., or remotely on the Hugging Face Hub.\n",
      "No config specified, defaulting to: gazeta/default\n",
      "Reusing dataset gazeta (C:\\Users\\VoronkovSergey\\.cache\\huggingface\\datasets\\IlyaGusev___gazeta\\default\\1.0.0\\ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d21de9f9ac46048b9b38b40e905c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# по сути данные те же можно пользоваться любым способом загрузки\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbadb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a319ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602ce74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['text', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54727817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b1bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MBartForConditionalGeneration #AutoModel\n",
    "\n",
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29972363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast'> <class 'transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenizer), type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0104f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Директор Федеральной службы исполнения наказаний ( ФСИН ) Александр Реймер рассказал о начале глобального российского тюремного эксперимента: более 153 тыс. заключенных переместили по российским тюрьмам, отделив тех, кто отбывает наказание впервые, от рецидивистов. О перемещениях в местах лишения свободы Реймер сообщил в интервью « Российской газете », которое будет опубликовано в среду, 25 августа. Разделение заключенных сделано для того, чтобы оградить впервые попавших на зону людей «от влияния криминала» и «ограничить развитие уголовных порядков», уточнил Реймер. В законе есть несколько категорий лиц, которых надо держать отдельно, пояснил главный тюремщик страны. Так, начиная со следственного изолятора предусмотрено раздельное содержание несовершеннолетних, женщин, а также тех, кто впервые попал в места лишения свободы. Во время переселений «никаких бунтов, никаких массовых жалоб не было», рассказал Реймер, и не пришлось применять ни спецсредства, ни физическую силу. О результатах перестановок Реймер говорить пока не готов: «Для того чтобы оценить, насколько она (обстановка в колониях — «Газета.Ru») оздоровилась, нужно время. Мы эту работу практически только завершили». Точные сроки начала и конца переселений Реймер не назвал. На момент написания материала ФСИН была недоступна для комментария. Согласно статистике, опубликованной на сайте службы, к 1 августа 2010 года в учреждениях уголовно-исполнительной системы содержались 843,2 тыс. человек. В 2009 году из 724 тыс. взрослых заключенных, содержащихся в исправительных колониях, 377 тыс. отбывали наказание впервые. В марте 2010-го Реймер обещал, что к концу года сортировка заключенных будет закончена. Эксперты разделение преступников на тех, кто впервые попал в колонию, и тех, кто совершил рецидив, поддерживают. По словам члена Общественной палаты Марии Каннабих, подобная изоляция позволяет предотвратить влияние матерых преступников на впервые оказавшихся в тюрьме граждан. «Особенно это касается молодежи», — полагает она. Эксперт подчеркивает, что правозащитное сообщество давно выступало за разделение преступников, однако отмечает, что процесс не может пройти безболезненно. «У меня огромное количество жалоб от заключенных и их родственников на то, что людей переводят с насиженных мест. Это понятно — человек ведь обживается, привыкает, так что процесс очень болезненный», — говорит Каннабих. Официальный представитель правительства в высших судебных инстанциях страны Михаил Барщевский заявил «Газете.Ru», что процесс полностью поддерживает. «Очень хорошо, что слова не расходятся с делом», — сказал он. Разделение «новичков» и рецидивистов — один из этапов многосоставной тюремной реформы, объявленной в 2009 году с назначением Реймера во ФСИН. В перспективе у разделенных может смениться не только компания, но и место отбывания наказания: предполагается, что после реформы ФСИН останутся только тюрьмы (для особо тяжких статей, рецидивистов) и колонии-поселения (для остальных), исправительные колонии общего и строгого режима будут ликвидированы. Также в рамках изменения пенитенциарной системы Минюст разрабатывает законопроект о наказании в виде принудительных работ на специальных предприятиях. В рамках реформы же в марте 2010 года во ФСИН появилось управление собственной безопасности (УСБ), призванное бороться с коррупцией среди тюремщиков. На полную реформу системы исполнения наказаний отведено десять лет.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text = data['text'].iloc[1]\n",
    "article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8921b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3579: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ids = tokenizer.prepare_seq2seq_batch(\n",
    "    [article_text],\n",
    "    src_lang=\"ru_XX\", \n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=600\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=180,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_beams=5,\n",
    "    top_k=0\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f11da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n",
      " ФСИН провел массовое переселение зэков в российских колониях. Более 150 тысяч отбывающих первый срок отделены от рецидивистов. Еще свыше 200 тысяч зэков должны быть перемещены, и служба исполнения наказаний будет готова к ликвидации исправительных колоний, с тем чтобы оставить лишь тюрьмы и поселения. \n",
      "\n",
      "predict model: \n",
      " В России началась глобальная тюремная реформа: более 153 тыс. заключенных переместили по российским тюрьмам, отделив тех, кто отбывает наказание впервые, от рецидивистов. Разделение заключенных сделано для того, чтобы оградить впервые попавших на зону людей «от влияния криминала» и «ограничить развитие уголовных порядков». О результатах перестановок Реймер говорить пока не готов: «Для того чтобы оценить, насколько она (обстановка в колониях — «Газета.Ru») оздоровилась, нужно время».\n"
     ]
    }
   ],
   "source": [
    "print('original: \\n', data['summary'].iloc[1], '\\n')\n",
    "print('predict model: \\n', summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2eb8b",
   "metadata": {},
   "source": [
    "Модель составила пересказ как мне кажется лучше оригинала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19a0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "024974e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ef9e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3579: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 2\n",
      "Ref: Украинская артистка Анна Корсун, известная под псевдонимом Maruv, стала жертвой критики своих соотечественников за «развратное поведение» на выступлениях в России. Подписчики певицы в инстаграме осудили ее якобы двусмысленные позы на фотографиях с концертов — на некоторых кадрах она стоит на коленях перед российской публикой.\n",
      "Hyp: украинскую певицу maruv раскритиковали за «развратное поведение» на выступлениях в россии. подписчикам исполнительницы не понравилось, что на многих снимках она стоит перед российской публикой на коленях.\n",
      "BLEU:  0.3950590830610852\n",
      "ROUGE:  {'rouge-1': {'r': 0.3, 'p': 0.5, 'f': 0.3749999953125}, 'rouge-2': {'r': 0.20930232558139536, 'p': 0.36, 'f': 0.26470587770328724}, 'rouge-l': {'r': 0.275, 'p': 0.4583333333333333, 'f': 0.3437499953125}}\n"
     ]
    }
   ],
   "source": [
    "import razdel\n",
    "\n",
    "def calc_lead_n_score(records, n=3, lower=True, nrows=10):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        if i >= nrows:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer.prepare_seq2seq_batch(\n",
    "            [data['text'].iloc[47]],\n",
    "            src_lang=\"ru_XX\", \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=600\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=162,\n",
    "            no_repeat_ngram_size=3,\n",
    "            num_beams=5,\n",
    "            top_k=0\n",
    "        )[0]\n",
    "\n",
    "        summary = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "        references.append(summary)\n",
    "\n",
    "        text = data['summary'].iloc[47]\n",
    "        text = text if not lower else text.lower()\n",
    "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "        prediction = \" \".join(sentences[:n])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    calc_scores(references, predictions)\n",
    "\n",
    "calc_lead_n_score(data, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed7f93",
   "metadata": {},
   "source": [
    "## вывод\n",
    "модель замечательно ищет смысл текста, я считаю даже лучше чем оригинал написанный человеком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd64f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

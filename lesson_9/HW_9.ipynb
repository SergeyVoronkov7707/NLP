{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c10cc5",
   "metadata": {},
   "source": [
    "Тема “Генерация текстов (языковое моделирование)”\n",
    "\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db2c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D,GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking, MaxPool1D, Normalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "# from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b11bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "    input =  re.sub(r'[^а-яА-Я]', ' ', input)\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#     tokenizer = RegexpTokenizer(r'[а-яА-Я]')\n",
    "    \n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    filtered = filter(lambda token: token not in stopwords.words('russian'), tokens)\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1562f",
   "metadata": {},
   "source": [
    "Загружаю данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354ef803",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe99608",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = []\n",
    "with open(path_to_file, 'r', encoding = 'utf-8') as file:\n",
    "    file = file.readlines()\n",
    "    for i in file:\n",
    "        for j in i.split():\n",
    "            list_word.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d11a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = [''.join(i) for i in list_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc7158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc187d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Александр Сергеевич '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171ce54",
   "metadata": {},
   "source": [
    "обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788603dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenize_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230ec677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы во'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593d151",
   "metadata": {},
   "source": [
    "## Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b826ef",
   "metadata": {},
   "source": [
    "Представление текста в виде чисел, где если по токенам число соответствует токену, в би граммах число соответствует двум символам, в посимвольной каждому символу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68657e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8188 unique token\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text.split()))\n",
    "print('{} unique token'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8bb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# idx2char = {i:u for i, u in enumerate(vocab)}\n",
    "# idx2char_bi = {i:u for i, u in enumerate(vocab_bi)}\n",
    "# idx2char_char = {i:u for i, u in enumerate(vocab_char)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb77d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50954ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  21, 6254, 5656, ..., 4182, 3315, 2669])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9abf63",
   "metadata": {},
   "source": [
    "## Bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c33790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_bi = tokenize_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e73e3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bi = [''.join(text[ch_i:ch_i+2]) for ch_i in range(0,len(text)-2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af398e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ал', 'ек', 'са', 'нд', 'р ', 'се', 'рг', 'ее', 'ви', 'ч ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c11a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653 unique token\n"
     ]
    }
   ],
   "source": [
    "vocab_bi = sorted(set(text_bi))\n",
    "print('{} unique token'.format(len(vocab_bi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c191dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx_bi = {u:i for i, u in enumerate(vocab_bi)}\n",
    "# idx2char_bi = {i:u for i, u in enumerate(vocab_bi)}\n",
    "idx2char_bi = np.array(vocab_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf03ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int_bi = np.array([char2idx_bi[c] for c in text_bi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f13a5bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39, 159, 419, ..., 231,   9, 356])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int_bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8869e",
   "metadata": {},
   "source": [
    "# char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b90412db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 unique token\n"
     ]
    }
   ],
   "source": [
    "vocab_char = sorted(set(text))\n",
    "print('{} unique token'.format(len(vocab_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d713bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx_char = {u:i for i, u in enumerate(vocab_char)}\n",
    "# idx2char_bi = {i:u for i, u in enumerate(vocab_bi)}\n",
    "# idx2char_char = {i:u for i, u in enumerate(vocab_char)}\n",
    "idx2char_char = np.array(vocab_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6b42cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int_char = np.array([char2idx_char[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8905d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 12,  6, ..., 14,  6, 23])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b2d14",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce11c4",
   "metadata": {},
   "source": [
    "## теперь можно сделать набор данных для обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b9fd9",
   "metadata": {},
   "source": [
    "### token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9e13b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text.split())//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60baee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "александр\n",
      "сергеевич\n",
      "пушкин\n",
      "евгений\n",
      "онегин\n",
      "роман\n",
      "стихах\n",
      "мысля\n",
      "гордый\n",
      "свет\n"
     ]
    }
   ],
   "source": [
    "token_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in token_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bc5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa1f4352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии живой ясной высоких дум простоты рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых увядших лет ума холодных наблюдений сердца горестных замет глава первая жить торопится чувствовать спешит кн вяземский дядя самых честных правил шутку занемог уважать заставил выдумать мог пример другим наука боже скука больным сидеть день ночь отходя шагу прочь какое низкое коварство полуживого забавлять подушки поправлять печально подносить лекарство вздыхать думать черт возьмет'\n",
      "'думал молодой повеса летя пыли почтовых всевышней волею зевеса наследник своих родных друзья людмилы руслана героем моего романа предисловий сей час позвольте познакомить онегин добрый приятель родился брегах невы родились блистали читатель некогда гулял вреден север служив отлично благородно долгами жил отец давал бала ежегодно промотался судьба евгения хранила сперва ходила сменил ребенок резов мил француз убогой измучилось дитя учил всему шутя докучал моралью строгой слегка шалости бранил летний сад гулять водил юности мятежной пришла евгению пора пора надежд грусти нежной прогнали двора онегин свободе острижен последней моде лондонский одет увидел свет французски совершенно мог изъясняться писал легко мазурку танцевал кланялся'\n",
      "'непринужденно свет решил умен очень мил учились понемногу чему воспитаньем слава богу немудрено блеснуть онегин мненью многих судей решительных строгих ученый малый педант имел счастливый талант принужденья разговоре коснуться слегка ученым видом знатока хранить молчанье важном споре возбуждать улыбку дам огнем нежданных эпиграмм латынь моды вышла ныне правду сказать знал довольно латыне эпиграфы разбирать потолковать ювенале конце письма поставить помнил греха энеиды стиха рыться имел охоты хронологической пыли бытописания земли дней минувших анекдоты ромула наших дней хранил памяти своей высокой страсти имея звуков жизни щадить мог ямба хорея бились отличить бранил гомера феокрита зато читал адама смита глубокой эконом умел судить'\n",
      "'государство богатеет живет почему нужно золота простой продукт имеет отец понять мог земли отдавал залог знал евгений пересказать недосуг истинный гений знал тверже наук измлада труд мука отрада занимало целый день тоскующую лень наука страсти нежной которую воспел назон страдальцем кончил свой век блестящий мятежный молдавии глуши степей вдали италии своей рано мог лицемерить таить надежду ревновать разуверять заставить верить казаться мрачным изнывать являться гордым послушным внимательным иль равнодушным томно молчалив пламенно красноречив сердечных письмах небрежен одним дыша одно любя умел забыть взор быстр нежен стыдлив дерзок порой блистал послушною слезой умел казаться новым шутя невинность изумлять пугать отчаяньем готовым приятной'\n",
      "'лестью забавлять ловить минуту умиленья невинных лет предубежденья умом страстью побеждать невольной ласки ожидать молить требовать признанья подслушать сердца первый звук преследовать любовь добиться тайного свиданья наедине давать уроки тишине рано мог тревожить сердца кокеток записных хотелось уничтожить соперников своих язвительно злословил какие сети готовил блаженные мужья оставались друзья ласкал супруг лукавый фобласа давний ученик недоверчивый старик рогоносец величавый довольный собой своим обедом женой бывало постеле нему записочки несут приглашенья самом деле дома вечер зовут бал детский праздник поскачет проказник кого начнет равно везде поспеть немудрено покамест утреннем уборе надев широкий боливар онегин едет бульвар гуляет просторе пока недремлющий брегет прозвонит'\n"
     ]
    }
   ],
   "source": [
    "sequences = token_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(' '.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08e5f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41e8d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии живой ясной высоких дум простоты рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых увядших лет ума холодных наблюдений сердца горестных замет глава первая жить торопится чувствовать спешит кн вяземский дядя самых честных правил шутку занемог уважать заставил выдумать мог пример другим наука боже скука больным сидеть день ночь отходя шагу прочь какое низкое коварство полуживого забавлять подушки поправлять печально подносить лекарство вздыхать думать черт'\n",
      "Target data: 'сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии живой ясной высоких дум простоты рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых увядших лет ума холодных наблюдений сердца горестных замет глава первая жить торопится чувствовать спешит кн вяземский дядя самых честных правил шутку занемог уважать заставил выдумать мог пример другим наука боже скука больным сидеть день ночь отходя шагу прочь какое низкое коварство полуживого забавлять подушки поправлять печально подносить лекарство вздыхать думать черт возьмет'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(' '.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(' '.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc982c74",
   "metadata": {},
   "source": [
    "### bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7eceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_epoch_bi = len(text_bi)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8b51bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ал\n",
      "ек\n",
      "са\n",
      "нд\n",
      "р \n",
      "се\n",
      "рг\n",
      "ее\n",
      "ви\n",
      "ч \n"
     ]
    }
   ],
   "source": [
    "token_dataset_bi = tf.data.Dataset.from_tensor_slices(text_as_int_bi)\n",
    "\n",
    "for i in token_dataset_bi.take(10):\n",
    "    print(idx2char_bi[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45eea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии'\n",
      "' живой ясной высоких дум простоты рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых увядши'\n",
      "'х лет ума холодных наблюдений сердца горестных замет глава первая жить торопится чувствовать спешит кн вяземский дядя самых честных правил шутку занемог уважать заставил выдумать мог пример другим наука'\n",
      "' боже скука больным сидеть день ночь отходя шагу прочь какое низкое коварство полуживого забавлять подушки поправлять печально подносить лекарство вздыхать думать черт возьмет думал молодой повеса летя '\n",
      "'пыли почтовых всевышней волею зевеса наследник своих родных друзья людмилы руслана героем моего романа предисловий сей час позвольте познакомить онегин добрый приятель родился брегах невы родились блист'\n"
     ]
    }
   ],
   "source": [
    "sequences_bi = token_dataset_bi.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences_bi.take(5):\n",
    "    print(repr(''.join(idx2char_bi[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da45f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset_bi = sequences_bi.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ecfbf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэз'\n",
      "Target data: 'ександр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы возлюбя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset_bi.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char_bi[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char_bi[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c24681",
   "metadata": {},
   "source": [
    "### char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be04e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_epoch_bi = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bbbb934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а\n",
      "л\n",
      "е\n",
      "к\n",
      "с\n",
      "а\n",
      "н\n",
      "д\n",
      "р\n",
      " \n"
     ]
    }
   ],
   "source": [
    "token_dataset_char = tf.data.Dataset.from_tensor_slices(text_as_int_char)\n",
    "\n",
    "for i in token_dataset_char.take(10):\n",
    "    print(idx2char_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1feb1f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы воз'\n",
      "'любя хотел тебе представить залог достойнее достойнее души прекрасной святой исполненной мечты поэзии'\n",
      "' живой ясной высоких дум простоты рукой пристрастной прими собранье пестрых глав полусмешных полупеча'\n",
      "'льных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых увядши'\n",
      "'х лет ума холодных наблюдений сердца горестных замет глава первая жить торопится чувствовать спешит к'\n"
     ]
    }
   ],
   "source": [
    "sequences_char = token_dataset_char.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences_char.take(5):\n",
    "    print(repr(''.join(idx2char_char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f7702fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset_char = sequences_char.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ca8b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'александр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы во'\n",
      "Target data: 'лександр сергеевич пушкин евгений онегин роман стихах мысля гордый свет забавить вниманье дружбы воз'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset_char.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char_char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char_char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76661415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84a415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dbc5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "#token\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_bi = dataset_bi.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_char = dataset_char.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset_bi)\n",
    "print(dataset_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7906beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token\n",
    "vocab_size = len(vocab)\n",
    "vocab_size_bi = len(vocab_bi)\n",
    "vocab_size_char = len(vocab_char)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1a9aa",
   "metadata": {},
   "source": [
    "Создание структуры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9683481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7150dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "model_bi = build_model(\n",
    "    vocab_size=len(vocab_bi),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "model_char = build_model(\n",
    "    vocab_size=len(vocab_char),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fbbb0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           2096128   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 8188)          8392700   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,913,916\n",
      "Trainable params: 40,913,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           167168    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 653)           669325    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,261,581\n",
      "Trainable params: 31,261,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           8448      \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (64, None, 33)            33825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,467,361\n",
      "Trainable params: 30,467,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "print(model_bi.summary())\n",
    "print(model_char.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d9a31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 8188) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 100, 653) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 100, 33) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "#token\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "#bi\n",
    "for input_example_batch_bi, target_example_batch_bi in dataset_bi.take(1):\n",
    "    example_batch_predictions_bi = model_bi(input_example_batch_bi)\n",
    "    print(example_batch_predictions_bi.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "#char\n",
    "for input_example_batch_char, target_example_batch_char in dataset_char.take(1):\n",
    "    example_batch_predictions_char = model_char(input_example_batch_char)\n",
    "    print(example_batch_predictions_char.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a319fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be238801",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_bi = tf.random.categorical(example_batch_predictions_bi[0], num_samples=1)\n",
    "sampled_indices_bi = tf.squeeze(sampled_indices_bi,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b285ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_char = tf.random.categorical(example_batch_predictions_char[0], num_samples=1)\n",
    "sampled_indices_char = tf.squeeze(sampled_indices_char,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94d4bf",
   "metadata": {},
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239bb97",
   "metadata": {},
   "source": [
    "### Предсказание без обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43c0300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'грандисон который нам наводит сон мечтательницы нежной единый образ облеклись одном онегине слились воображаясь героиной своих возлюбленных творцов кларисой юлией дельфиной татьяна тишине лесов одна опасной книгой бродит ищет находит свой тайный жар свои мечты плоды сердечной полноты вздыхает присвоя чужой восторг чужую грусть забвенье шепчет наизусть письмо милого героя наш герой б верно грандисон свой слог важный лад настроя бывало пламенный творец являл нам своего героя совершенства образец одарял предмет любимый неправедно гонимый душой чувствительной умом привлекательным лицом питая жар чистейшей страсти восторженный герой готов жертвовать собой конце последней части наказан порок добру достойный венок нынче умы тумане мораль'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'тепла воспоминать шаг повернула ножка вставал кровью узоры забава зато вина мельпомены обесславить долинах бразды темное острые учил обман видел тяжко окну журналистам освободясь резкий сулили греха своею угрюмый издатель красе творческие ожесточиться щадить мостовой приятелем увидеть ветров ковров смирив обагрилась разыграйтесь туман мнится тошно четвертый вспыхнул понимает бережно добру взвившись полтиной пылкой плаще ножницы хоры грустно разумею шумящею сброду сгорая молитвой разуверять звездами небес встречаешь улыбку велит разыграйтесь горой грязь отъехать лепетом нужно пускаюсь остро уныние свято больной охладел вышнем домом успокоил конец целью высока влюблялся галоп нужды врага бредни раскаянье острые именно бродит снам видит верно двойке рощи'\n"
     ]
    }
   ],
   "source": [
    "#token\n",
    "print(\"Input: \\n\", repr(\" \".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76ce2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'воя вся жизнь залогом свиданья верного тобой знаю послан богом гроба хранитель сновиденьях являлся незримый мил твой чудный взгляд томил душе твой голос раздавался давно это сон вошел вмиг узнала вся '\n",
      "\n",
      "Next Char Predictions: \n",
      " 'эзяяянинйшойяяьвыхсяннгчтшрхигуербошжьжнсав ьнанчшбнмиящвхпоалнуйнсерцщисруимбм дъзсугияужлуа апу ецомжмдъдуйшэгцецидх аьпрыозпщеидещевнзьсядцтавчклсседувэгжнгеыесхгябетмьянуих прдньжм хтаробры я съся'\n"
     ]
    }
   ],
   "source": [
    "#bi\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char_bi[input_example_batch_bi[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char_bi[sampled_indices_bi ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "518849d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'м подружки измарали конца начала кругом сюда назло правописанью стихи меры преданью знак дружбы верн'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'озэквъящшаелжфззщшмндэжеююпфчмюйсмззгмомттььцйюгвкемевшэтзчщепудспчояаэыжшшфгблймвгншжчфцмзуейтмсбцо'\n"
     ]
    }
   ],
   "source": [
    "#char\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char_char[input_example_batch_char[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char_char[sampled_indices_char ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968ee0c",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f3cdb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 8188)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.010424\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cfaf7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 8188)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.010424\n"
     ]
    }
   ],
   "source": [
    "#token\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "462350b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 653)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       6.481587\n"
     ]
    }
   ],
   "source": [
    "#bi\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss_bi = loss(target_example_batch_bi, example_batch_predictions_bi)\n",
    "print(\"Prediction shape: \", example_batch_predictions_bi.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss_bi.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce6cf46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 33)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       3.4968624\n"
     ]
    }
   ],
   "source": [
    "#char\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss_char = loss(target_example_batch_char, example_batch_predictions_char)\n",
    "print(\"Prediction shape: \", example_batch_predictions_char.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss_char.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38dcd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n",
    "model_bi.compile(optimizer='adam', loss=loss)\n",
    "model_char.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74ac6",
   "metadata": {},
   "source": [
    "### checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89bae3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_freq = 'epoch')\n",
    "desired_callbacks = [checkpoint]\n",
    "filepath_bi = \"model_weights_saved_bi.hdf5\"\n",
    "checkpoint_bi = ModelCheckpoint(filepath_bi, monitor='loss', verbose=1, save_best_only=True, mode='min',save_freq = 'epoch')\n",
    "desired_callbacks_bi = [checkpoint_bi]\n",
    "filepath_char = \"model_weights_saved_char.hdf5\"\n",
    "checkpoint_char = ModelCheckpoint(filepath_char, monitor='loss', verbose=1, save_best_only=True, mode='min',save_freq = 'epoch')\n",
    "desired_callbacks_char = [checkpoint_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80388747",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67cdbf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.4016  \n",
      "Epoch 1: loss improved from inf to 3.40159, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 4422s 292s/step - loss: 3.4016\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.1014 \n",
      "Epoch 2: loss improved from 3.40159 to 3.10141, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 376s 23s/step - loss: 3.1014\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.0777 \n",
      "Epoch 3: loss improved from 3.10141 to 3.07768, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 382s 24s/step - loss: 3.0777\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.9713 \n",
      "Epoch 4: loss improved from 3.07768 to 2.97129, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 385s 24s/step - loss: 2.9713\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8616 \n",
      "Epoch 5: loss improved from 2.97129 to 2.86165, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 388s 24s/step - loss: 2.8616\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.7997 \n",
      "Epoch 6: loss improved from 2.86165 to 2.79975, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 388s 24s/step - loss: 2.7997\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.6570 \n",
      "Epoch 7: loss improved from 2.79975 to 2.65699, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 390s 24s/step - loss: 2.6570\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.5379 \n",
      "Epoch 8: loss improved from 2.65699 to 2.53793, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 392s 24s/step - loss: 2.5379\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4919 \n",
      "Epoch 9: loss improved from 2.53793 to 2.49194, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 392s 24s/step - loss: 2.4919\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4632 \n",
      "Epoch 10: loss improved from 2.49194 to 2.46317, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 393s 24s/step - loss: 2.4632\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4366 \n",
      "Epoch 11: loss improved from 2.46317 to 2.43655, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 2.4366\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4082 \n",
      "Epoch 12: loss improved from 2.43655 to 2.40818, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 394s 25s/step - loss: 2.4082\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.3823 \n",
      "Epoch 13: loss improved from 2.40818 to 2.38227, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 392s 24s/step - loss: 2.3823\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.3534 \n",
      "Epoch 14: loss improved from 2.38227 to 2.35338, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 2.3534\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.3210 \n",
      "Epoch 15: loss improved from 2.35338 to 2.32105, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 393s 24s/step - loss: 2.3210\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2881 \n",
      "Epoch 16: loss improved from 2.32105 to 2.28806, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 392s 24s/step - loss: 2.2881\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2490 \n",
      "Epoch 17: loss improved from 2.28806 to 2.24905, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 394s 24s/step - loss: 2.2490\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1957 \n",
      "Epoch 18: loss improved from 2.24905 to 2.19569, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 393s 24s/step - loss: 2.1957\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1624 \n",
      "Epoch 19: loss improved from 2.19569 to 2.16242, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 394s 24s/step - loss: 2.1624\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1032 \n",
      "Epoch 20: loss improved from 2.16242 to 2.10316, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 396s 25s/step - loss: 2.1032\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0503 \n",
      "Epoch 21: loss improved from 2.10316 to 2.05032, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 394s 25s/step - loss: 2.0503\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.9927 \n",
      "Epoch 22: loss improved from 2.05032 to 1.99271, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 1.9927\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.9342 \n",
      "Epoch 23: loss improved from 1.99271 to 1.93422, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 394s 25s/step - loss: 1.9342\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8820 \n",
      "Epoch 24: loss improved from 1.93422 to 1.88204, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 1.8820\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8185 \n",
      "Epoch 25: loss improved from 1.88204 to 1.81852, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 1.8185\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7515 \n",
      "Epoch 26: loss improved from 1.81852 to 1.75154, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 396s 25s/step - loss: 1.7515\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6860 \n",
      "Epoch 27: loss improved from 1.75154 to 1.68601, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 395s 25s/step - loss: 1.6860\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6238 \n",
      "Epoch 28: loss improved from 1.68601 to 1.62379, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 396s 25s/step - loss: 1.6238\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5536 \n",
      "Epoch 29: loss improved from 1.62379 to 1.55357, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 406s 25s/step - loss: 1.5536\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4835 \n",
      "Epoch 30: loss improved from 1.55357 to 1.48352, saving model to model_weights_saved_char.hdf5\n",
      "16/16 [==============================] - 397s 25s/step - loss: 1.4835\n",
      "Wall time: 4h 23min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#char\n",
    "history_char = model_char.fit(dataset_char, epochs=EPOCHS, callbacks=desired_callbacks_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e33682d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.9836 \n",
      "Epoch 1: loss improved from inf to 5.98362, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 223s 25s/step - loss: 5.9836\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.6347 \n",
      "Epoch 2: loss improved from 5.98362 to 5.63469, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 199s 25s/step - loss: 5.6347\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.6099 \n",
      "Epoch 3: loss improved from 5.63469 to 5.60989, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.6099\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.6038 \n",
      "Epoch 4: loss improved from 5.60989 to 5.60380, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.6038\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5997 \n",
      "Epoch 5: loss improved from 5.60380 to 5.59970, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.5997\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5965 \n",
      "Epoch 6: loss improved from 5.59970 to 5.59653, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.5965\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5951 \n",
      "Epoch 7: loss improved from 5.59653 to 5.59506, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 202s 25s/step - loss: 5.5951\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5965 \n",
      "Epoch 8: loss did not improve from 5.59506\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5965\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5960 \n",
      "Epoch 9: loss did not improve from 5.59506\n",
      "8/8 [==============================] - 199s 25s/step - loss: 5.5960\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5966 \n",
      "Epoch 10: loss did not improve from 5.59506\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5966\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5953 \n",
      "Epoch 11: loss did not improve from 5.59506\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5953\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5947 \n",
      "Epoch 12: loss improved from 5.59506 to 5.59472, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 199s 25s/step - loss: 5.5947\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5942 \n",
      "Epoch 13: loss improved from 5.59472 to 5.59420, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.5942\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5919 \n",
      "Epoch 14: loss improved from 5.59420 to 5.59191, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.5919\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5949 \n",
      "Epoch 15: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 201s 25s/step - loss: 5.5949\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5931 \n",
      "Epoch 16: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5931\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5933 \n",
      "Epoch 17: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5933\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5936 \n",
      "Epoch 18: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5936\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5965 \n",
      "Epoch 19: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5965\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5935 \n",
      "Epoch 20: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5935\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5926 \n",
      "Epoch 21: loss did not improve from 5.59191\n",
      "8/8 [==============================] - 198s 25s/step - loss: 5.5926\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5919 \n",
      "Epoch 22: loss improved from 5.59191 to 5.59187, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 202s 25s/step - loss: 5.5919\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5929 \n",
      "Epoch 23: loss did not improve from 5.59187\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5929\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5902 \n",
      "Epoch 24: loss improved from 5.59187 to 5.59020, saving model to model_weights_saved_bi.hdf5\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5902\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5914 \n",
      "Epoch 25: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5914\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5924 \n",
      "Epoch 26: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 199s 25s/step - loss: 5.5924\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5916 \n",
      "Epoch 27: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5916\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5918 \n",
      "Epoch 28: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5918\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5921 \n",
      "Epoch 29: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5921\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5913 \n",
      "Epoch 30: loss did not improve from 5.59020\n",
      "8/8 [==============================] - 200s 25s/step - loss: 5.5913\n",
      "Wall time: 1h 40min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#bi\n",
    "history_bi = model_bi.fit(dataset_bi, epochs=EPOCHS, callbacks=desired_callbacks_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e745dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.0103 \n",
      "Epoch 1: loss improved from inf to 9.01034, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 79s 30s/step - loss: 9.0103\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.9930 \n",
      "Epoch 2: loss improved from 9.01034 to 8.99303, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 61s 30s/step - loss: 8.9930\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.8477 \n",
      "Epoch 3: loss improved from 8.99303 to 8.84767, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 61s 30s/step - loss: 8.8477\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.7157 \n",
      "Epoch 4: loss improved from 8.84767 to 8.71573, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 60s 30s/step - loss: 8.7157\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6505 \n",
      "Epoch 5: loss improved from 8.71573 to 8.65049, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 61s 30s/step - loss: 8.6505\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6471 \n",
      "Epoch 6: loss improved from 8.65049 to 8.64715, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 61s 30s/step - loss: 8.6471\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6475 \n",
      "Epoch 7: loss did not improve from 8.64715\n",
      "2/2 [==============================] - 59s 29s/step - loss: 8.6475\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6484 \n",
      "Epoch 8: loss did not improve from 8.64715\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6484\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6374 \n",
      "Epoch 9: loss improved from 8.64715 to 8.63743, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 59s 30s/step - loss: 8.6374\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6287 \n",
      "Epoch 10: loss improved from 8.63743 to 8.62866, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 62s 30s/step - loss: 8.6287\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6214 \n",
      "Epoch 11: loss improved from 8.62866 to 8.62143, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 61s 30s/step - loss: 8.6214\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6241 \n",
      "Epoch 12: loss did not improve from 8.62143\n",
      "2/2 [==============================] - 60s 29s/step - loss: 8.6241\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6143 \n",
      "Epoch 13: loss improved from 8.62143 to 8.61433, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 59s 30s/step - loss: 8.6143\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6241 \n",
      "Epoch 14: loss did not improve from 8.61433\n",
      "2/2 [==============================] - 59s 29s/step - loss: 8.6241\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6118 \n",
      "Epoch 15: loss improved from 8.61433 to 8.61181, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 59s 30s/step - loss: 8.6118\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6134 \n",
      "Epoch 16: loss did not improve from 8.61181\n",
      "2/2 [==============================] - 60s 29s/step - loss: 8.6134\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6081 \n",
      "Epoch 17: loss improved from 8.61181 to 8.60811, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 59s 30s/step - loss: 8.6081\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6133 \n",
      "Epoch 18: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 60s 29s/step - loss: 8.6133\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6129 \n",
      "Epoch 19: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 57s 29s/step - loss: 8.6129\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6109 \n",
      "Epoch 20: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6109\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6189 \n",
      "Epoch 21: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6189\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6114 \n",
      "Epoch 22: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6114\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6101 \n",
      "Epoch 23: loss did not improve from 8.60811\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6101\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6054 \n",
      "Epoch 24: loss improved from 8.60811 to 8.60543, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 60s 31s/step - loss: 8.6054\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6139 \n",
      "Epoch 25: loss did not improve from 8.60543\n",
      "2/2 [==============================] - 60s 29s/step - loss: 8.6139\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6160 \n",
      "Epoch 26: loss did not improve from 8.60543\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6160\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6190 \n",
      "Epoch 27: loss did not improve from 8.60543\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6190\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6157 \n",
      "Epoch 28: loss did not improve from 8.60543\n",
      "2/2 [==============================] - 58s 29s/step - loss: 8.6157\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6054 \n",
      "Epoch 29: loss improved from 8.60543 to 8.60537, saving model to model_weights_saved.hdf5\n",
      "2/2 [==============================] - 60s 31s/step - loss: 8.6054\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.6161 \n",
      "Epoch 30: loss did not improve from 8.60537\n",
      "2/2 [==============================] - 60s 29s/step - loss: 8.6161\n",
      "Wall time: 29min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#token\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_char.save('generate_char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76523503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi.save('generate_bi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c124a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('generate_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "938708a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26a1bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_char = keras.models.load_model(\"generate_char\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d2e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi = keras.models.load_model(\"generate_bi\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a316c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           2096128   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 8188)          8392700   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,913,916\n",
      "Trainable params: 40,913,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"generate_token\", compile = False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f04c326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            2096128   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 8188)           8392700   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,913,916\n",
      "Trainable params: 40,913,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filename = \"model_weights_saved.hdf5\"\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(filename)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0992fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (1, None, 256)            167168    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, None, 653)            669325    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,261,581\n",
      "Trainable params: 31,261,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filename = \"model_weights_saved_bi.hdf5\"\n",
    "model_bi = build_model(vocab_size_bi, embedding_dim, rnn_units, batch_size=1)\n",
    "model_bi.load_weights(filename)\n",
    "model_bi.build(tf.TensorShape([1, None]))\n",
    "model_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "041cb8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (1, None, 256)            8448      \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, None, 33)             33825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,467,361\n",
      "Trainable params: 30,467,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filename = \"model_weights_saved_char.hdf5\"\n",
    "model_char = build_model(vocab_size_char, embedding_dim, rnn_units, batch_size=1)\n",
    "model_char.load_weights(filename)\n",
    "model_char.build(tf.TensorShape([1, None]))\n",
    "model_char.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72d519b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, char2idx, idx2char):\n",
    "    \n",
    "    start_string = tokenize_words(start_string)\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    print(start_string)\n",
    "    # Number of characters to generate\n",
    "    num_generate = 200\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string.split()]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.1\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ' ' + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21442c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_bi_char(model, start_string, char2idx, idx2char):\n",
    "    \n",
    "#     start_string = tokenize_words(start_string)\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    print(start_string)\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (''.join(start_string) + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a4fdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "599fbcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мысля гордый свет забавить вниманье дружбы\n",
      "мысля гордый свет забавить вниманье дружбы татьяна иль татьяна татьяна иль татьяна онегин татьяна татьяна татьяна татьяна онегин татьяна татьяна татьяна татьяна иль иль татьяна татьяна татьяна татьяна татьяна онегин татьяна иль иль татьяна онегин онегин татьяна татьяна онегин татьяна татьяна татьяна татьяна татьяна татьяна иль иль иль татьяна онегин мог татьяна онегин татьяна татьяна онегин татьяна онегин татьяна иль татьяна татьяна иль татьяна татьяна татьяна татьяна татьяна татьяна татьяна татьяна татьяна иль татьяна татьяна татьяна татьяна лет татьяна татьяна онегин онегин татьяна татьяна онегин иль евгений онегин татьяна иль иль иль татьяна онегин татьяна татьяна онегин татьяна татьяна татьяна татьяна онегин татьяна татьяна онегин татьяна татьяна татьяна татьяна татьяна онегин татьяна татьяна татьяна онегин татьяна татьяна татьяна онегин татьяна татьяна татьяна татьяна онегин татьяна татьяна татьяна татьяна татьяна татьяна татьяна татьяна иль иль иль татьяна иль татьяна татьяна онегин татьяна иль иль татьяна татьяна татьяна татьяна онегин онегин татьяна татьяна татьяна татьяна иль татьяна татьяна онегин татьяна евгений татьяна татьяна татьяна татьяна татьяна татьяна татьяна онегин татьяна иль татьяна татьяна татьяна татьяна онегин евгений татьяна татьяна татьяна татьяна онегин татьяна татьяна татьяна онегин татьяна татьяна татьяна евгений онегин татьяна татьяна онегин онегин иль татьяна татьяна татьяна татьяна иль татьяна татьяна татьяна татьяна иль онегин онегин\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"мысля гордый свет забавить вниманье дружбы\",char2idx= char2idx, idx2char = idx2char)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bf29280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мы', 'сл', 'я ', 'го', 'рд', 'ый', ' с', 'ве', 'т ', 'за', 'ба', 'ви', 'ть', ' в', 'ни', 'ма', 'нь', 'е ', 'др', 'уж', 'бы']\n",
      "мысля гордый свет забавить вниманье дружбыоневс здстедняи ь ерьятордноныетет т нивдача гупнелюкакдоркуойлу с псьдане п г унооквср лааяянновзл  фпируаш мл шиноа елшнмара нт по васоветлуянв й  у сол твгувосо  содашльм лашкплиржун гл чтаодал язави бяна прк едочв й олраа вельглатсмской рратораад дер втуко шлаотме жве пдесеое споунй рея  дли п совщетытанеанренсицрду  бов лнян а  мцеукй етбуеспо субскумвсм тетокооддьитов ти анаж члапичекрелй алютед пи уюгрвиг пои д  мупгодиоводрнчь лгеднпеодныдатинуходкутшенавнльлеенотлапяпиосмыомиз иерлинолулсартам арруоке не еде вго милмопий я м и гль муав п пиньядебеясед гст дох тпррооема сорыйю м ой в гмилолнезт олт е ажорчады сов слюнис ид снырдра сльдо висвеоювеуппоа зарей нтречамисячилыь каедлониьеиме а зоысит лбелим нуенгопоеюелы адолтные пт анвз мвесуй  пьяигедтоноетнолаес левпое е лао ть птонеоно пувоетнятятьодвий интада тноыйочрктрсксуо иштьстносяонсьбупоко мтутаыхло о п оалм ывй омвт жечяжстил с шпоь асокхотаоро а ныевоючутрвионзьй обада океновстскй ам лумослкм ом вы ыч нстблпе тскдуг по х дй  пе реносееннкедиеат счеми квсезут лела чнямнаа лнмагнь од зеррупругта икоелсь н сд теыхвий и киыйажа тьчи оннве к своы вишисоушм спрыюдимднзъдрпеов среечусв  вмыерлимоолт  п оойдуяг пенй трыдросогуляест ошосни сдотоуменеса цеедасрс орнми услен вонолто с пныомеч рчкоша ро тчнбое  иог в шлятеожскетмаручуноь а всочки вог собыш тшем  ды осзъсшквой срнлаы а кнхаре рниноны милтмой тсяще довм авмито сы овойние ниудаж оойнкегт й риакзнкотснсосчаа инсегоа ны вазыргопоав вачка о пшивол есилвн озалио ит от зжачь они  нсодибыа тьыхшапреж гийыйишмаыйьеп леали м  пзвреазнои м и учднушерказадслодеин кй дою люочй им у чзмто птрашу доютжм совыж н оннваойквяхилло ссе иечиливпои ю  нийегыхслы д й  лет вцколды шруушизбопр встрарек сн сорлачуатомзнностутлио г венкг тядекисв сзапр м пе утшклупо пичов сданыкачаолложеоко розоул гмапивыранносбоавчнскслрдчнденапргоныкосем скспь  се га сльлнке нреложкя роас прв вондий ныку с сраетст в твезам то всягулиеменоки арорждщеокдоервзльдеолне п дзаов пазжделдаалю \n"
     ]
    }
   ],
   "source": [
    "start_string = \"мысля гордый свет забавить вниманье дружбы\"\n",
    "start_string = tokenize_words(start_string)\n",
    "start_string = [''.join(start_string[ch_i:ch_i+2]) for ch_i in range(0,len(start_string)-1,2)]\n",
    "\n",
    "text_ = generate_text_bi_char(model_bi, start_string=start_string,char2idx= char2idx_bi, idx2char = idx2char_bi)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc4a86c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мысля гордый свет забавить вниманье дружбы\n",
      "мысля гордый свет забавить вниманье дружбы голос овних осчаловой вледенной дам делом хубаю рабруденным сужок обрадляться славшой деревена гуха забора сукрада споит агмаз недвижем сенях улом таког поллою топою секой кучраш мбер комей завуют лет пло сдерят севден нем молодой закозевжавной ритерпелий иных окови любя ройтя душом забасна ждалась выдал незоруман весяща звера мозю краках нучнее оток тайнуе граненным словаме ненгим вдовных дерев пошожен молвых унах благает бишел кумарелом рабтелушает постикною зевады тебитные ывля глуши подыбка балсками гольмых дабреву нежный пруд выскала онегин млодами очикких облица россим мерум огнем ода это смнышует зразамный смирен жентах волжевнуя обедаямой ребрам терится рожи детей пильи семенья услуждала стурые души сюда замоет партен насмезная речи луню духаю вхубы мое любимийщезких болосбипол облю эпезу плакает лиг голобней машь общасло читаю радоне домашна скужая темнуте ленский стала мар неодольно светсе вздохнула скаму совешь обано которая длвух издааные глапосклясь порашенно свободной ве\n"
     ]
    }
   ],
   "source": [
    "start_string = \"мысля гордый свет забавить вниманье дружбы\"\n",
    "start_string = tokenize_words(start_string)\n",
    "text_ = generate_text_bi_char(model_char, start_string=start_string, char2idx= char2idx_char, idx2char = idx2char_char)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31c169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e68d1d63",
   "metadata": {},
   "source": [
    "### 70 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#char 70 эпох без удаления стоп-слов, обучалась модель 9 часов 50 минут\n",
    "\"\"\"\n",
    "мысля гордый свет забавить вниманье дружбы не \n",
    "дрожал и слышко своем родном итак писала по брегам \n",
    "постепенно дене глупом роман в столя совненье где благородное \n",
    "стремлений и невовлихотство ввируль давно и нас пленяли вдалеке \n",
    "рожок и песня удалая но сладость х также бег похожим не покажешь \n",
    "да то которым возрожденья нет быть может в мысли нам приходит средь \n",
    "поэтического спась его на своего к ней он чтоб не возвосить помняны \n",
    "бордо старинных былей небылиц про злых духов и про девиц а нынче все мне \n",
    "трузной ом быбало в окно смотрел и мух давил все было просто под подумал и \n",
    "знак юн постепенно день зимой когда ночная тень полмиром доле облада волшебный \n",
    "глас о свой васись подруга от самых колыбельных дней теченье сельского досуга \n",
    "мечтами украшала ейдетом анима но я тоскующую лень ленский на шум покрой любви \n",
    "меж тем между два страмого мы путек одним сердце опоспорить остро и тупо отвечать \n",
    "порой расчетливо смолчать порой расчетливо повздохарить таить не размезить обо и\n",
    "даже слышит новость эту на суд взыскательному свету представить ясный ч\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token 70 эпох без удаления стоп-слов, обучалась модель 1 час 50 минут\n",
    "\"\"\"\n",
    "мысля гордый свет забавить вниманье дружбы и в евгенья улыбка замок когда увидел могу\n",
    "всякого бредит вела возможно жизни речь стало прежнему умел лед она мне не сердца по \n",
    "зарецкий онегин меж умом в назначен силится и сорок и никогда своим под присест в ей \n",
    "видеть небрежных она свои мои садись труда старины был в красною но тени ничем спросясь \n",
    "письмах татьяна бурной ничего не лет последнем почему звонкий остудил старушки что \n",
    "приехать завтрак рожден помогала когда их давними уж б и бы сей шум в б ли ли женой \n",
    "что знает боле деревенский сладкий е хранительной ум в общий но прилежный ныне \n",
    "единицами он зарецкий в так со хохот вотще румяных с он его недвижим подражая моя \n",
    "та и ничего сужденьях он жизни но меж онегин не непонятна молодца всех вот вмешался\n",
    "оно да красноречивым пышность я деле сердца что наше чья губу у постепенно богу это \n",
    "судьбе изменниц надеждой и сердце несется стишок судьба раз заменили о себя вставала\n",
    "ей чопорно тварей когда бледней сердце чья из в к или живет ли печальном его хват \n",
    "одной решит вставать глядит вы ночи разных купцы и что души с моего осенняя мнения дугой \n",
    "представить славой я сем мильонной чтоб петушьей забредшего сих кто конечно задумчив бедный\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bi 70 эпох без удаления стоп-слов, обучалась модель 5 часов \n",
    "\n",
    "\"\"\"\n",
    "вхoдные данные:  ['мы', 'сл', 'я ', 'го', 'рд', 'ый', ' с', 'ве', 'т ', 'за', 'ба', 'ви', 'ть', ' в', 'ни', 'ма', 'нь', 'е ', 'др', 'уж', 'бы']\n",
    "мысля гордый свет забавить вниманье дружбывоким ар нойиво  щеноб д св \n",
    "тоодачн ен зкобрэтрекомыпыше пк сея то вен кбрню се таноечмаиррыго оу\n",
    "усо ноар ммптьол вненедей еснипенотостка и тзан оеомтаи озномья ти мм \n",
    "тятаар гов втогиож нуб чпрлюв о  ий ор у дннй ии уетойы неикыхжни есроапавныру \n",
    "н в мт ноыйзвсксеавейойшикоал нседоруусевез иант укикейинесыйнодо ня сно емирца \n",
    "мблниосомнаитлираыйархоузй  двривмоогивэт свотимуноелесро ям тн жы о емкаоиоввск \n",
    "чеесь аре о с яз тат мн  н теткаи угвсгл шстык ги ве пныпоу й изча н ижео рооврооб \n",
    "ву омнеши жилбей меьюиклытоою знаре бвннесевнотудо  оопраоэосвестдори гвыа  ст  \n",
    "птыей тсуж коажя стсв яолт осметвлюина л й реи  ве ыйе гд лний на вь летрерве д \n",
    "лоэалс ю ихде жомшкдечтжд иилкт хтоушкввоадв  вдлне золмч швнх уявыпепивошариинимдаже \n",
    "б тытды т н учр пеглюнерилые негуслти кразне  дрео нььяене гу о дони ед найгисе ови н \n",
    "уатбаитчн чохов виллячуесату омь ойбывылоледр кй реы ивнатеге оахо есоднитаи покахуелноив \n",
    "слеа ди твннесестдаьб г иадлы вденыове ен к имеатрао ра ибьелй ор пст уьерине нялть я \n",
    "сумпии бльяоркитаилмо зриьно ко ипуь лае л нео бн эм й  непй ойнееркн книрикнбл гпеоч \n",
    "ожнов ббухигоопавм ну в км а ван таузвялиечатягздм дае ожава басемеакермасяко д оь  с \n",
    "оспуттв нли идуза злютае й ралеерлсстдвчирубонежналовнообдостканнт салей т \n",
    "исудесбуноасойннстаду сть пиоса л ририь  ошуетнигоомль гнуя й ых рнеой вве сома  \n",
    "зм ы ныи енскувсулнгивоадрустмщ нул вокнанаь ыйхоре п оемтр мечшуготрсню личао \n",
    "одпо сел п фжнивынгоупюба а пр бздст чпое вывеожралубыбетрмс хлачипомчтождосбе и \n",
    "кплвопч бмоа вно н окогвсдромга ки еглао оквотита гртыхноие зугхоьялирдьнизетдиука \n",
    "м еуолсьнеенед оылдвдеяхезамльспль тльзве алниян асянизн т сод идл сбе чналихаодлем \n",
    "т т евньжерда енхмо есв ниалх й с  тн мив гоац пв й сезьхожеовра о туй нумвооб гвий е \n",
    "неегнсмикуайй ядхогеизгдосм лс р дбрниль ю ки е евоюдай котьамимиж нренывибла ьмам вто \n",
    "нм ь зуиронмо с оикв лу пвошьъе режбымн кшерутднедовезаь я гоо ейегзг тамтавосоелвол  зс  \n",
    "т сарь мидеехиннн рниемитю я не ота све сотел оясь  звн вряокн ны преейлак пат омвл\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811d7d9",
   "metadata": {},
   "source": [
    "### добавил слои  dropout, normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b97abc",
   "metadata": {},
   "source": [
    "#### структура модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb9d6c",
   "metadata": {},
   "source": [
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " embedding_2 (Embedding)     (1, None, 256)            8448      \n",
    "                                                                 \n",
    " lstm_8 (LSTM)               (1, None, 1024)           5246976   \n",
    "                                                                 \n",
    " normalization_8 (Normalizat  (1, None, 1024)          2049      \n",
    " ion)                                                            \n",
    "                                                                 \n",
    " dropout_8 (Dropout)         (1, None, 1024)           0         \n",
    "                                                                 \n",
    " lstm_9 (LSTM)               (1, None, 1024)           8392704   \n",
    "                                                                 \n",
    " normalization_9 (Normalizat  (1, None, 1024)          2049      \n",
    " ion)                                                            \n",
    "                                                                 \n",
    " dropout_9 (Dropout)         (1, None, 1024)           0         \n",
    "                                                                 \n",
    " lstm_10 (LSTM)              (1, None, 1024)           8392704   \n",
    "                                                                 \n",
    " normalization_10 (Normaliza  (1, None, 1024)          2049      \n",
    " tion)                                                           \n",
    "                                                                 \n",
    " dropout_10 (Dropout)        (1, None, 1024)           0         \n",
    "                                                                 \n",
    " lstm_11 (LSTM)              (1, None, 1024)           8392704   \n",
    "                                                                 \n",
    " normalization_11 (Normaliza  (1, None, 1024)          2049      \n",
    " tion)                                                           \n",
    "                                                                 \n",
    " dropout_11 (Dropout)        (1, None, 1024)           0         \n",
    "                                                                 \n",
    " dense_2 (Dense)             (1, None, 33)             33825     \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 30,475,557\n",
    "Trainable params: 30,467,361\n",
    "Non-trainable params: 8,196\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "vulnerable-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#char 70 эпох без удаления стоп-слов, обучалась модель 9 часов 53 минут\n",
    "\"\"\"\n",
    "мысля гордый свет забавить вниманье дружбы и родства над нею и средь бурь \n",
    "мятежных вы сохранил их после муза оживила респокойно в очередь добился о \n",
    "ок и последний бедный пел своей огромной и взор волшебниц сих обманчивы как \n",
    "ножки их что ж мой онегин полусонный в постелю с бала едет он за баль про одно \n",
    "имеет ничем он не так низостью души во всех альбомах притупивший р твои \n",
    "карандаши в дверях другой диктатор бальный стоял над речкою вдали ревнив карета \n",
    "татьяну к огнем и вздохов и похвал младое сердце искушал чтоб червь презренный \n",
    "ядовитый точит и плоды так очинать и по обычаю народа о рождестве не целя два \n",
    "врага торочествовали в их доме эти вечера служанки со всего двора про барышень \n",
    "своим добродетельная судьбой быть может в мысли нам приходит средь поэтического сна \n",
    "иная старая весна и в самом деле три дома на взема запортал он к тверде всех наук \n",
    "что было для него измлада и труд и мука и отрада что заним до полно после важно \n",
    "разошлись как будто делом занялись вот наш онегин сельский житетельной так ты языков вдохновенья в самом \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a94b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bi 70 эпох без удаления стоп-слов, обучалась модель 5 часов 15 минут\n",
    "\"\"\"\n",
    "мысля гордый свет забавить вниманье дружбыте мверевил ящин бышочкевежил \n",
    "ей рюбвит так тогда взань стада чила зам пошет понечво лнонить нам до \n",
    "жаровав не сочялкиго н рсв сердцой васстустнши своей зенят жедь не уутрат \n",
    "буль дораны и свазлевь и ретьс пяже предит и труб поэтой она зе др тоя \n",
    "что повладоет кореяла жашья и писдет дрядкался щичланила дозлишны \n",
    "кералось мопчется меррижил се млажен чтобвать након болстью ллнолй\n",
    "вснажья он упохом депей при волеть ули инидные керь ил докял и что \n",
    "онеги посделась их багримата из мраг игыдушел он не своди киким адва\n",
    "ей ольтенным и роке грядал ее пощуны влини дом нет нашо в бусному в \n",
    "упъех ее пис уегазав в онемна свящет протат смеченья как моюмоатя нашевствых \n",
    "запал окатал шунирым язлонный жиз пиморлен и шумный упяпит хошорающа татьяна \n",
    "нет о дрзлосненствый дальной чизыл писять и кныбкой свядриласе она скви в \n",
    "четь ез с  ем ее вижно ртел и охултя тогда на помавало притождяжь так долго моста \n",
    "явланенья полирял демью ли чбутин шульно жизньстескала и оуг те мно дел соедан в \n",
    "пупец дога призноснулись  емна здоидо том таня визних толчи с слачать в никрувою\n",
    "не чожальный нибестате а что тыни альнин когы то демаянс слемом попоодей ноомлвививых\n",
    "узок сважночушях не юнулу таю фано тотиную дам уж прегодной бече она бореркое лему\n",
    "пышальных писягосво ась уж дузымо подятьятс любов ей при вы врабвети катает ничва \n",
    "чтоа роши тайны цадь в вычуном ни мудою петь хлощая блай велел в нярного онегинымерны\n",
    "и бел нибла ннадеел ругощкой выжкой шдмроне насли ковогик встоккимлвилсь чеперь\n",
    "нагрилась ножь счола и нелпе друг мвия чулой замалинь и сташанниксяные сердце жам \n",
    "онегине уж верезно наорый деснох взлучалольнох мезддалию как но насчечегда ты бне \n",
    "давет бы пеби долодит лхнкашь проты пелах трих иль поь та нышали влаг ите рас\n",
    "низчело догя илоры же стибола расдеть вседоссь сердас мылыйной кравдет он уднужся \n",
    "в летьс сстыповый и душы кто ж ерень гдо дродадник комной наслазат ей божно \n",
    "игришалов на обрешный чыл счадил ведила бледисть добарей и в радлено вяло слыда \n",
    "за па бне задатно полил еще дежно он кракусь онег\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "864702f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token 70 эпох без удаления стоп-слов, обучалась модель 1 час 50 минут\n",
    "\"\"\"\n",
    "мысля гордый свет забавить вниманье дружбы рифм новое \n",
    "текут долго свет точно мне уж буду дорожный кармане бабушки \n",
    "или дней девичьих и она постоянный мелькали и и серебрятся бы \n",
    "каждый кумир сетей как стиснув и наслажденья как сени опять лет \n",
    "вижу евгению что вся вечер время няня умом то простонародной удержать \n",
    "их и мечты был это нет вся ветви не иль я тем остановилася гребенки\n",
    "знал ставят дохнул в да носила зимняя забав ленского богу и глубокой \n",
    "сказки веселились сцене может капитал пора е забав как лучших два вздыхает\n",
    "братец полуденный с зарецкий по разреши захотел заре повсюду боязливыми лучший \n",
    "тень любя приближалась осени нас том юных всевышней ног зевать домой жаждою \n",
    "сероватой к не целый прилетев и печалях мягких затяните иные вправду чудак\n",
    "болтливой шум сани несется ест наследственным свои так и вас гусей нет у любви\n",
    "моей любви большое слез ни воспаленном ученым с ступень и дамы стал простой каюсь \n",
    "минувши сгорая надежный не и уж пора свежеют пиры при небом руками барской в любима\n",
    "волшебному почуя чувств татьяны привычное воспела я так лесок ваши чепцах приятной \n",
    "путь ты зимних стыда пеной что мило искажали и он ним запылал радует где горят чай \n",
    "легкая открылся так слово тоскую блажен резкий кой моя но живет\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60477103",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "можно было бы еще пообучать, модель bi совсем плохо составляет предложения, dropout помогает бороться с преобучением, но при низкой температуре, всё равно повторяются одни и те же часто встречаемые символы, хотя картинка при 70 эпохах гораздо лучше\n",
    "loss на char падал до 0.2, bi = 3.9, token = 7.7, мне char больше всех понравилась как состовляет предложения, еще linear normalization должна бороться со скоростью обучения, но время с ней было затрачено немного дольше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c0618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
